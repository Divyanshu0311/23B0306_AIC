### **ViT vs. Convolutional Neural Networks**<br>
1) Architecture:<br>
* CNNs: They tilize convolutional layers to extract features and build spatial hierarchies.
* ViTs: They divide images into patches, embed these patches into vectors, and process them using Transformer layers (self-attention and feed-forward networks).
2) Feature Extraction:<br>
* CNNs: They capture local features progressively through convolutions and pooling.
* ViTs: Model global relationships from the start using self-attention mechanisms.
3) Computational Cost:
* CNNs: They are generally more efficient, especially for high-resolution images.
* ViTs: They computationally expensive due to quadratic complexity of self-attention.
4) Training Complexity:
* CNNs: They are easier to train with well-established techniques and less computational resources.
* ViTs: They require careful tuning, advanced augmentation, and substantial computational power.
5) Performance:
* CNNs: They show strong performance on many vision tasks, especially with moderate-sized datasets.
* ViTs: They achieve state-of-the-art results on large-scale datasets and excel in transfer learning.
<br>
<br>
#### Resources used by me are :-<br>
* (https://www.v7labs.com/blog/vision-transformer-guide)
* (https://arxiv.org/pdf/2010.11929)
* (https://www.mdpi.com/2076-3417/13/9/5521)
* (https://www.youtube.com/watch?v=kJJoB19ayjg)
* (https://www.youtube.com/watch?v=xXcnbjKYrec)
